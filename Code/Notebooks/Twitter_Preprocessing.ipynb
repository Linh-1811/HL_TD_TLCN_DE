{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e20db6e",
   "metadata": {},
   "source": [
    "## Airline Tweets pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "547ffaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import các thư viện \n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from autocorrect import Speller\n",
    "from nltk.stem import PorterStemmer\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1b7ad47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Đọc dữ liệu từ tệp CSV vào DataFrame\n",
    "df = pd.read_csv('../data/final_train_df.csv', encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Trộn ngẫu nhiên các dòng trong DataFrame\n",
    "df_shuffled=df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1230c7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phân chia dữ liệu theo cảm xúc\n",
    "positive_df = df[df['airline_sentiment'] == 'positive']  # Lọc các tweet có cảm xúc tích cực\n",
    "neutral_df = df[df['airline_sentiment'] == 'neutral']  # Lọc các tweet có cảm xúc trung lập\n",
    "negative_df = df[df['airline_sentiment'] == 'negative']  # Lọc các tweet có cảm xúc tiêu cực"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bfbf30",
   "metadata": {},
   "source": [
    "### Initial pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41e63205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment  airline_sentiment_confidence negativereason  \\\n",
       "0           neutral                        1.0000            NaN   \n",
       "1          positive                        0.3486            NaN   \n",
       "2           neutral                        0.6837            NaN   \n",
       "3          negative                        1.0000     Bad Flight   \n",
       "4          negative                        1.0000     Can't Tell   \n",
       "\n",
       "   negativereason_confidence         airline airline_sentiment_gold  \\\n",
       "0                        NaN  Virgin America                    NaN   \n",
       "1                     0.0000  Virgin America                    NaN   \n",
       "2                        NaN  Virgin America                    NaN   \n",
       "3                     0.7033  Virgin America                    NaN   \n",
       "4                     1.0000  Virgin America                    NaN   \n",
       "\n",
       "         name negativereason_gold  retweet_count  \\\n",
       "0     cairdin                 NaN              0   \n",
       "1    jnardino                 NaN              0   \n",
       "2  yvonnalynn                 NaN              0   \n",
       "3    jnardino                 NaN              0   \n",
       "4    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loại bỏ các dòng có dữ liệu trùng lặp trong cột 'text'\n",
    "df = df.drop_duplicates(['text'])\n",
    "\n",
    "# Kiểm tra và xóa các cột không cần thiết\n",
    "columns_to_drop = ['Unnamed: 0', 'tweet_id']  # Các cột cần loại bỏ\n",
    "df = df.drop(columns=[col for col in columns_to_drop if col in df.columns], axis=1)  # Loại bỏ các cột\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca3a78a",
   "metadata": {},
   "source": [
    "### Removing special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1863dcc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  @VirginAmerica What @dhepburn said.\n",
       "1    @VirginAmerica plus you've added commercials t...\n",
       "2    @VirginAmerica I didn't today... Must mean I n...\n",
       "3    @VirginAmerica it's really aggressive to blast...\n",
       "4    @VirginAmerica and it's a really big bad thing...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hàm làm sạch văn bản\n",
    "def clean(txt):\n",
    "    txt = txt.replace(\"()\", \"\")  # Loại bỏ các ký tự \"()\"\n",
    "    txt = txt.replace('(<a).*(>).*()', '')  # Loại bỏ các thẻ HTML\n",
    "    txt = txt.replace('(&amp)', '')  # Loại bỏ các ký tự đặc biệt như &amp\n",
    "    txt = txt.replace('(&gt)', '')  # Loại bỏ các ký tự đặc biệt như &gt\n",
    "    txt = txt.replace('(&lt)', '')  # Loại bỏ các ký tự đặc biệt như &lt\n",
    "    txt = txt.replace('(\\xa0)', ' ')  # Loại bỏ ký tự không phải không gian\n",
    "    return txt\n",
    "\n",
    "# Áp dụng hàm làm sạch cho cột 'text' trong DataFrame\n",
    "df['text'] = df['text'].apply(lambda x: clean(x))\n",
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496e127d",
   "metadata": {},
   "source": [
    "### Extracting all the hastags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0443b0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]                      12077\n",
       "[DestinationDragons]       70\n",
       "[fail]                     36\n",
       "[usairwaysfail]            21\n",
       "[customerservice]          21\n",
       "                        ...  \n",
       "[peanutsonaplatter]         1\n",
       "[letitgo]                   1\n",
       "[hotlanta]                  1\n",
       "[notmadeofmoney]            1\n",
       "[BlackBerry10]              1\n",
       "Name: tweet_hastags, Length: 1785, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trích xuất các hashtag và mentions từ văn bản\n",
    "df['tweet_hastags'] = df['text'].apply(lambda x: re.findall(\"#([a-zA-Z0-9_]{1,50})\", x))  # Tìm tất cả các hashtag\n",
    "df['tweet_hastags'].value_counts()  # Đếm số lần xuất hiện của các hashtag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5245d04a",
   "metadata": {},
   "source": [
    "### Extracting all the mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08063867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[united]                          3370\n",
       "[USAirways]                       2470\n",
       "[AmericanAir]                     2281\n",
       "[SouthwestAir]                    2090\n",
       "[JetBlue]                         1932\n",
       "                                  ... \n",
       "[SouthwestAir, TifffyHuang]          1\n",
       "[SouthwestAir, JasonWhitely]         1\n",
       "[SouthwestAir, SwagglikeBean]        1\n",
       "[SouthwestAir, SacIntlAirport]       1\n",
       "[AmericanAir, TilleyMonsta]          1\n",
       "Name: mentions, Length: 1020, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mentions'] = df['text'].apply(lambda x: re.findall(\"@([a-zA-Z0-9_]{1,50})\", x))  # Tìm tất cả các mentions\n",
    "df['mentions'].value_counts()  # Đếm số lần xuất hiện của các mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd16596",
   "metadata": {},
   "source": [
    "### Removing hastags and mentions from tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a966583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          What  said.\n",
       "1     plus you've added commercials to the experien...\n",
       "2     I didn't today... Must mean I need to take an...\n",
       "3     it's really aggressive to blast obnoxious \"en...\n",
       "4             and it's a really big bad thing about it\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Làm sạch annotation (xóa mentions và hashtags)\n",
    "def clean_annotation(tweet):\n",
    "    clean_tweet = re.sub(\"@[A-Za-z0-9_]+\", \"\", tweet)  # Xóa mentions\n",
    "    clean_tweet = re.sub(\"#[A-Za-z0-9_]+\", \"\", clean_tweet)  # Xóa hashtags\n",
    "    return clean_tweet\n",
    "\n",
    "# Áp dụng hàm làm sạch annotation cho cột 'text'\n",
    "df['tweets'] = df['text'].apply(lambda x: clean_annotation(x))\n",
    "df['tweets'].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7908953c",
   "metadata": {},
   "source": [
    "### Removing HTTP Links "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3031511e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          What  said.\n",
       "1     plus you've added commercials to the experien...\n",
       "2     I didn't today... Must mean I need to take an...\n",
       "3     it's really aggressive to blast obnoxious \"en...\n",
       "4             and it's a really big bad thing about it\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loại bỏ URL và ký tự đặc biệt\n",
    "df['tweets'] = df['tweets'].apply(lambda x: re.sub(r'https?:\\/\\/\\S*', '', x, flags=re.MULTILINE))\n",
    "df['tweets'].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a3e111",
   "metadata": {},
   "source": [
    "### Converting to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ea59740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           what said.\n",
       "1    plus you've added commercials to the experienc...\n",
       "2    i didn't today... must mean i need to take ano...\n",
       "3    it's really aggressive to blast obnoxious \"ent...\n",
       "4             and it's a really big bad thing about it\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chuyển đổi tất cả các từ về chữ thường\n",
    "df['tweets'] = df['tweets'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "df['tweets'].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e30862a",
   "metadata": {},
   "source": [
    "### Removing punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "76ab8874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                            what said\n",
       "1    plus youve added commercials to the experience...\n",
       "2    i didnt today must mean i need to take another...\n",
       "3    its really aggressive to blast obnoxious enter...\n",
       "4              and its a really big bad thing about it\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loại bỏ ký tự đặc biệt không phải từ hoặc khoảng trắng\n",
    "df['tweets'] = df['tweets'].str.replace('[^\\w\\s]','')\n",
    "df['tweets'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca6812a",
   "metadata": {},
   "source": [
    "### De-emojify tweets to sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20b1bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xóa emoji trong cột 'tweets'\n",
    "f = open(\"../Notebooks/emoji_regex.txt\", \"r\")\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(f.read(), flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5176a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                            what said\n",
       "1    plus youve added commercials to the experience...\n",
       "2    i didnt today must mean i need to take another...\n",
       "3    its really aggressive to blast obnoxious enter...\n",
       "4              and its a really big bad thing about it\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweets'] = df['tweets'].apply(lambda x: remove_emoji(x))  # Áp dụng loại bỏ emoji\n",
    "df['tweets'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df413c6d",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea7c028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển đổi các từ về dạng gốc (lemmatization) sử dụng spacy\n",
    "import spacy\n",
    "load_model = spacy.load('en_core_web_sm', disable=['parser', 'ner'])  # Tải mô hình ngôn ngữ Anh nhỏ của spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f02cddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(x):\n",
    "    doc = load_model(x)  # Tạo đối tượng Doc từ văn bản\n",
    "    return \" \".join([token.lemma_ for token in doc])  # Lấy dạng gốc của từ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a6e383b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                             what say\n",
       "1    plus you ve add commercial to the experience t...\n",
       "2    I do not today must mean I need to take anothe...\n",
       "3    its really aggressive to blast obnoxious enter...\n",
       "4              and its a really big bad thing about it\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweets'] = df['tweets'].apply(lambda x: lemmatize(x))  # Áp dụng lemmatization cho cột 'tweets'\n",
    "df['tweets'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e273d6",
   "metadata": {},
   "source": [
    "### Part of speech tagging (POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "198f5c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phân tích cú pháp POS (Part of Speech) cho mỗi từ trong tweet\n",
    "from textblob import TextBlob\n",
    "\n",
    "def pos_tag(x):\n",
    "    result = TextBlob(x)  # Chuyển đổi văn bản thành đối tượng TextBlob\n",
    "    return result.tags  # Trả về các nhãn POS (từ loại)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "519814df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             [(what, WP), (say, VBP)]\n",
       "1    [(plus, CC), (you, PRP), (ve, VBP), (add, VB),...\n",
       "2    [(I, PRP), (do, VBP), (not, RB), (today, NN), ...\n",
       "3    [(its, PRP$), (really, RB), (aggressive, JJ), ...\n",
       "4    [(and, CC), (its, PRP$), (a, DT), (really, RB)...\n",
       "Name: tweets_tags, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "df['tweets_tags'] = df['tweets'].apply(lambda x: TextBlob(x).tags)\n",
    "df['tweets_tags'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1966d184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('TextBlob', 'NNP'), ('is', 'VBZ'), ('working', 'VBG'), ('correctly', 'RB'), ('now', 'RB')]\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "blob = TextBlob(\"TextBlob is working correctly now.\")\n",
    "print(blob.tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c32d11",
   "metadata": {},
   "source": [
    "### Named Entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f4db7532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Định nghĩa hàm NER (Named Entity Recognition) và thực hiện stemming trên tweet\n",
    "def ner(x):\n",
    "    return ne_chunk(pos_tag(word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f2f5743e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             [(what, WP), (say, VBP)]\n",
       "1    [(plus, CC), (you, PRP), (ve, VBP), (add, VB),...\n",
       "2    [(I, PRP), (do, VBP), (not, RB), (today, NN), ...\n",
       "3    [(its, PRP$), (really, RB), (aggressive, JJ), ...\n",
       "4    [(and, CC), (its, PRP$), (a, DT), (really, RB)...\n",
       "Name: ner_tweets, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ner_tweets'] = df['tweets'].apply(lambda x: ner(x))\n",
    "df['ner_tweets'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13085d1d",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8d4255b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                             what say\n",
       "1          plu you ve add commerci to the experi tacki\n",
       "2    i do not today must mean i need to take anoth ...\n",
       "3    it realli aggress to blast obnoxi entertain in...\n",
       "4               and it a realli big bad thing about it\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Thực hiện stemming cho các từ trong tweet sử dụng PorterStemmer\n",
    "stemming = PorterStemmer()\n",
    "# Áp dụng stemming cho các từ trong tweet\n",
    "df['tweets'] = df['tweets'].apply(lambda x: \" \".join([stemming.stem(word) for word in x.split()]))  \n",
    "df['tweets'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4537b2c7",
   "metadata": {},
   "source": [
    "### Spell Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "669eef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra và sửa lỗi chính tả trong văn bản\n",
    "def spell_check(x):\n",
    "    check = Speller(lang='en')  # Khởi tạo Speller từ thư viện autocorrect\n",
    "    return check(x)  # Sửa lỗi chính tả cho văn bản"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9aa1e6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                             what say\n",
      "1            pl you ve add commerce to the expert tack\n",
      "2     i do not today must mean i need to take not trip\n",
      "3    it really address to blast obnoxi entertain in...\n",
      "4               and it a really big bad thing about it\n",
      "5    serious would pay 30 a flight for seat that do...\n",
      "6    ye nearly every time i fli vx thi âear wormâ w...\n",
      "7    really miss a prime opportun for man without h...\n",
      "8                          well i didntâbut now i do d\n",
      "9    it be ama and arxiv an hour early you re too g...\n",
      "Name: tweets, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra 10 hàng đầu tiên của DataFrame để xem dữ liệu sau khi sửa lỗi chính tả\n",
    "df_sample = df.head(10).copy()  # Tạo bản sao để tránh SettingWithCopyWarning\n",
    "df_sample['tweets'] = df_sample['tweets'].apply(spell_check)  # Áp dụng hàm spell_check\n",
    "print(df_sample['tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f06093c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra chính tả sử dụng thư viện SpellChecker\n",
    "import pandas as pd\n",
    "from spellchecker import SpellChecker \n",
    "\n",
    "# Khởi tạo SpellChecker\n",
    "spell = SpellChecker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "91a5feaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kiểm tra chính tả\n",
    "def spell_check(x):\n",
    "    if pd.isnull(x):  # Kiểm tra nếu x là NaN\n",
    "        return x\n",
    "    words = x.split()\n",
    "    corrected = []\n",
    "    for word in words:\n",
    "        if word in spell:  # Nếu từ không sai\n",
    "            corrected.append(word)\n",
    "        else:\n",
    "            # Lấy ứng viên từ tập hợp\n",
    "            candidates = spell.candidates(word)\n",
    "            if candidates:  # Kiểm tra nếu candidates không phải là None\n",
    "                corrected.append(next(iter(candidates)))  # Lấy ứng viên đầu tiên\n",
    "            else:\n",
    "                corrected.append(word)  # Nếu không có ứng viên, thêm từ gốc\n",
    "    return ' '.join(corrected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6aa1902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_check_with_progress(df):  \n",
    "    # Hàm này kiểm tra và sửa lỗi chính tả cho từng dòng của cột 'tweets' trong DataFrame.\n",
    "    for index, row in df.iterrows():  \n",
    "        # Lặp qua từng dòng của DataFrame, trả về chỉ số (`index`) và nội dung dòng (`row`).\n",
    "        df.at[index, 'tweets'] = spell_check(row['tweets'])  \n",
    "        # Gọi hàm `spell_check` để kiểm tra và sửa lỗi chính tả cho nội dung trong cột 'tweets'.\n",
    "        # Gán giá trị đã được sửa lỗi vào vị trí tương ứng trong DataFrame.\n",
    "        if index % 100 == 0:  \n",
    "            # Nếu chỉ số dòng là bội số của 100.\n",
    "            print(f\"Processed {index} rows\")  \n",
    "            # In thông báo tiến trình, cho biết đã xử lý bao nhiêu dòng.\n",
    "    return df  \n",
    "    # Trả về DataFrame đã được xử lý toàn bộ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "47661526",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('final_df_train_second.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telekafka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
